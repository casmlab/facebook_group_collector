{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Collector Workflow\n",
    "\n",
    "\n",
    "The CASM Lab Facebook Collector projects follow our internal standard approach to social media data:\n",
    "\n",
    "1. collect\n",
    "2. cache\n",
    "3. parse\n",
    "4. analyze\n",
    "\n",
    "Under the collect step live scripts for getting data in \"raw\" form. Here, raw means whatever default format for the data is. Usually this means JSON dumped by an API, but for scrapers it's whatever data structure and format we decided to use. We are greedy in collection meaning we pull whatever data the API will let us have. \n",
    "\n",
    "Once we have \"raw\" data, we cache it by storing a read-only copy somewhere accessible to the whole team. Usually this storage step is handled by the collection script and isn't an extra scripting step. I call it out here though because it's conceptually important - social media data changes all the time, and caching lets us keep track of what the data looked like at the time of collection (e.g., what was returned, what structure was standard then).\n",
    "\n",
    "Next, we parse. Parsing scripts pull data from the read-only caches and put them in formats that are appropriate for analysis or whatever comes next. For instance, some of our Twitter user timeline tools collect data from search API, cache it, then parse it into a MySQL database for display on our Django-backed website. This leaves us with two related, but not identical, copies of the data - one in JSON from Twitter, and one in MySQL. Parsing scripts also do any data transformations that are necessary for analysis (e.g., converting timestamps, calculating user stats).\n",
    "\n",
    "Finally, we get to analyze the data. Often analysis is included in the same script as parsing, but sometimes analysis steps will live on their own. Some of the analysis will involve machine learning or natural language processing, but some will be simple word clouds or descriptive statistics.\n",
    "\n",
    "## Setup\n",
    "Note: This code has been tested on OS X 10.11.3 and Windows 10.\n",
    "\n",
    "\n",
    "1. Create a Facebook Web App on [https://developers.facebook.com](https://developers.facebook.com). Or your Facebook account needs to be granted at least Tester permission to modify and run a current web app;\n",
    "2. Clone the FacebookGroupCollector repo;\n",
    "3. Use Python 3;\n",
    "4. Open Command Prompt from the folder where ```facebook_group_fetch.html``` locates;\n",
    "5. Start a localhost at localhost:4000. We run ```python3 -m http.server 4000``` to set the localhost. (This only works in real command line.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "% python3 -m http.server 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facebook_group_grabdata.js\n",
    "- appId: the App ID on your Developer Dashboard\n",
    "\n",
    "### facebook_group_cache.py\n",
    "- group_id: the group/page id that you are grabbing data from. This will show up on the web page when you run the fetch.html code.\n",
    "- group_name: the group/page name that you are grabbing data from. This will show up on the web page when you run the fetch.html code.\n",
    "\n",
    "\n",
    "## Collect\n",
    "1. In the main directory, start a localhost at 4000. And open ```http://localhost:4000/scripts/facebook_group_fetch.html``` in your browser and input your page link. It could be a Facebook page or a Facebook group.\n",
    "2. Click the button and wait to grab the json data from the feed as the page says.\n",
    "3. When the data is prepared, click the link as the page asks to download the raw data.\n",
    "4. Check your raw-data-sample folder and see if it's there, if not, put it there for the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "At the first time you click the button on the webpage, a Facebook website about your verification would show up. Log in and repeat the previous steps. \n",
    "\n",
    "\n",
    "## Cache\n",
    "1. Setup and get group_id and group_name from the previous step.\n",
    "2. Run the ```cache.py``` file to clean raw file and add meta data including the ```Facebook group ID```, ```Group name```, ```last post ID```, ```last post```, and all other content (\"[data]\").\n",
    "\n",
    "Run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% run scripts/facebook_group_cache.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Prepare for Qualitative Analysis\n",
    "After downloading all data, we do a little curation with ```parse.py``` and ```toCSV.py```.\n",
    "\n",
    "#### Step 1. Parse data to wanted schema.\n",
    "\n",
    "Having all raw data in the directory RawData/, run the ```parse.py``` first to extract targeted information for future analysis including \n",
    "\n",
    "-\tmessage [the content of the entry]\n",
    "-\tpostId  [the id of the entry]\n",
    "-\tparentPostId  [if the current entry is a post, this is the id of its parent]\n",
    "-\tparentCommentId  [if the current entry is a comment, this is the id of its parent]\n",
    "-\tauthorName  [the author name of the current entry]\n",
    "-\tmetaData [including hasLink, hasEvent, hasPhoto, hasVideo and hasTags. Boolean type and the default value is False.]\n",
    "\n",
    "Run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% run scripts/facebook_group_parse.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output file will be one JSON file composed of all entries. And each entry looks like the example below.\n",
    "\n",
    "\t{\n",
    "  \t\t\"hasVideo\": false,\n",
    "  \t\t\"hasPhoto\": false,\n",
    "  \t\t\"hasLink\": true,\n",
    "  \t\t\"parentPostId\": \"\",\n",
    "  \t\t\"authorName\": \"Shenyun Shenny\",\n",
    "  \t\t\"hasEvent\": false,\n",
    "  \t\t\"message\": \"Please join AACN this Saturday morning at 11 AM  for yummy dim sum at Ming Hin (2168 South Archer Avenue, Chicago, IL) in Chinatown. \\n\\nRSVP on our Meetup page: http:\\/\\/meetu.ps\\/3mPFG\",\n",
    "  \t\t\"postId\": \"160475740743826_167108120080588\",\n",
    "  \t\t\"hasTags\": false,\n",
    "  \t\t\"parentCommentId\": \"\"\n",
    "\t}\n",
    "\n",
    "Now we have all clean data we need.\n",
    "\n",
    "#### Step 2. Convert JSON data into Excel-friendly file (csv).\n",
    "The next step is to put the data in a Excel form so that we can analyze them one by one and take notes. The reason to do this is to classify different topics and discover new issues or questions from the feed.\n",
    "\n",
    "The easist way to do this is to convert our JSON data into CSV data so that Excel can just open it in a nice format. And that's what ```toCSV.py``` file does. Run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% run scripts/facebook_group_toCSV.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And open the output file in Excel. It would be like the table below:\n",
    "\n",
    "| postId  | parentPostId | parentCommentId | authorName | message | hasVideo | hasPhoto | hasEvent | hasLink | hasTags |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| 160475740743826_167108120080588  |   |   | Shenyun Shenny  | Please join AACN this Saturday morning at 11 AM  for yummy dim sum at Ming Hin (2168 South Archer Avenue, Chicago, IL) in Chinatown. RSVP on our Meetup page: http://meetu.ps/3mPFG  | FALSE  | FALSE  | FALSE  | TRUE  | FALSE  |\n",
    "\n",
    "\n",
    "And now you can add you own column such as \"notes\" or \"categories\" to do further qualitative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
